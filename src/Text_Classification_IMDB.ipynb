{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "703_RNN_LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_r68uC9Whi"
      },
      "source": [
        "# MLA 703. RNN-LSTM [Analyse de sentiment]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvDUVNa9Whk"
      },
      "source": [
        "# Dans ce notebook, nous allons nous intéresser à des tâches d'analyse de sentiments\n",
        "# -> c'est à dire prédire un label de sentiment (ici positif ou négatif) à partir d'un texte\n",
        "\n",
        "# Ce notebook vise à approfondir : \n",
        "# - L'application du DL sur des données textuelles\n",
        "# - La compréhension des architectures RNN avancées comme les LSTM et les mécanismes d'attention\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfXF_H-f9Whk"
      },
      "source": [
        "# 1. Importation des modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtouzMU19Whl"
      },
      "source": [
        "# On importe les librairies usuelless\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# On désactive les warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_VmTtGs9Whl"
      },
      "source": [
        "## 1. Charger les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdY_7FnG9Whl"
      },
      "source": [
        "import pandas as pd\n",
        "#import os\n",
        "#os.system(\"kaggle datasets download -d utathya/imdb-review-dataset\")\n",
        "\n",
        "# On lit le fichier csv de la base d'avis de IMDB (qui doit être préalablement être placé dans le dossier ./data/)\n",
        "data = pd.read_csv('./imdb_master.csv',encoding=\"latin-1\")\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdhwnqjv9Whl",
        "outputId": "6552ffa0-c2a3-4513-9dfa-b39c34c0a939"
      },
      "source": [
        "# On visualise les données brutes\n",
        "print(data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Unnamed: 0   type  ...  label         file\n",
            "0               0   test  ...    neg      0_2.txt\n",
            "1               1   test  ...    neg  10000_4.txt\n",
            "2               2   test  ...    neg  10001_1.txt\n",
            "3               3   test  ...    neg  10002_3.txt\n",
            "4               4   test  ...    neg  10003_3.txt\n",
            "...           ...    ...  ...    ...          ...\n",
            "99995       99995  train  ...  unsup   9998_0.txt\n",
            "99996       99996  train  ...  unsup   9999_0.txt\n",
            "99997       99997  train  ...  unsup    999_0.txt\n",
            "99998       99998  train  ...  unsup     99_0.txt\n",
            "99999       99999  train  ...  unsup      9_0.txt\n",
            "\n",
            "[100000 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "AN2y7tRI9Whm",
        "outputId": "41ca857d-270c-45a2-e53d-7cf56fbe6771"
      },
      "source": [
        "# On visualise le tableau de données (en utilisant les méthodes de data)\n",
        "data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0_2.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10000_4.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10001_1.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10002_3.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "      <td>10003_3.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  type  ... label         file\n",
              "0           0  test  ...   neg      0_2.txt\n",
              "1           1  test  ...   neg  10000_4.txt\n",
              "2           2  test  ...   neg  10001_1.txt\n",
              "3           3  test  ...   neg  10002_3.txt\n",
              "4           4  test  ...   neg  10003_3.txt\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRQ0E0Y-9Whm"
      },
      "source": [
        "## 2. Formater/Préparer les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Ca-jfFFG9Whm",
        "outputId": "d1fc3022-9040-4ad8-a555-ddef9ad5f511"
      },
      "source": [
        "# FORMATAGE DES DONNEES\n",
        "\n",
        "# On supprimes les données sans label\n",
        "data = data[data.label != 'unsup']\n",
        "\n",
        "# On reformate les labels et entiers (pos = 0; neg = 1)\n",
        "data['label'] = data['label'].map({'pos': 1, 'neg': 0})\n",
        "\n",
        "# On supprime les champs inutiles\n",
        "data = data.drop(['Unnamed: 0','file'],axis=1)\n",
        "\n",
        "# On visualise le tableau de données\n",
        "data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                             review  label\n",
              "0  test  Once again Mr. Costner has dragged out a movie...      0\n",
              "1  test  This is an example of why the majority of acti...      0\n",
              "2  test  First of all I hate those moronic rappers, who...      0\n",
              "3  test  Not even the Beatles could write songs everyon...      0\n",
              "4  test  Brass pictures (movies is not a fitting word f...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "TAnq27Oc9Whm",
        "outputId": "451e1ddb-d5ab-4b73-d76e-1b172522bc30"
      },
      "source": [
        "# 2) FILTRER LES DONNEES\n",
        "#\n",
        "# Le nettoyage des données est une étape essentielle de pré-traitement pour optimiser l'apprentissage en aval\n",
        "#\n",
        "# Pour le texte, il s'agit de : \n",
        "# - normer le texte,  \n",
        "# - segmenter le texte en mots \n",
        "# - supprimer les mots peu porteurs d'information\n",
        "# - puis détermines les lemmes, de , etc...\n",
        "#\n",
        "\n",
        "# On importe la librarie nltk dédiée aux traitement du langage naturel\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# On peut utiliser l'environnement nltk spécialisé pour le traitement de texte\n",
        "# (WordNet, stopwords pré-appris sur des bases de données)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# On pré-traite le texte pour normaliser le texte en entrée\n",
        "# - On retire certains caractères spéciaux\n",
        "# - On force la casse en minuscule\n",
        "# - on retire tous les mots qui sont des \"stop_words\"\n",
        "# - on lemmatise les mots (~les formes canoniques)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "# On pré-traite les données et on les place dans le champs \"Processed reviews\"\n",
        "data['Processed_Reviews'] = data.review.apply(lambda x: preprocess_text(x))\n",
        "\n",
        "# On visualise les données\n",
        "data.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>Processed_Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>0</td>\n",
              "      <td>mr costner ha drag movie far longer necessary ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>0</td>\n",
              "      <td>example majority action film generic bore real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>0</td>\n",
              "      <td>first hate moronic rapper couldnt act gun pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>0</td>\n",
              "      <td>even beatles could write song everyone like al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>0</td>\n",
              "      <td>brass picture movie fit word really somewhat b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                  Processed_Reviews\n",
              "0  test  ...  mr costner ha drag movie far longer necessary ...\n",
              "1  test  ...  example majority action film generic bore real...\n",
              "2  test  ...  first hate moronic rapper couldnt act gun pres...\n",
              "3  test  ...  even beatles could write song everyone like al...\n",
              "4  test  ...  brass picture movie fit word really somewhat b...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ozMICP9Whn",
        "outputId": "0ba4381d-7a2e-41bc-a711-71dee3ab7aa9"
      },
      "source": [
        "# On découpe les phrases en \"mots\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# On ne retient que les 5,000 tokens les plus fréquents (dans le texte)\n",
        "max_features = 5000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(data['Processed_Reviews'])\n",
        "\n",
        "# On vectorise les mots\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"La phrase à encoder est : \\n  {} \\n\" .format(data['Processed_Reviews'][0]))\n",
        "\n",
        "# On vectorise les tokens en séquences numériques\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(data['Processed_Reviews'])\n",
        "\n",
        "print(\"La phrase vectorisée est : \\n {} \\n\". format(list_tokenized_train[0]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La phrase à encoder est : \n",
            "  mr costner ha drag movie far longer necessary aside terrific sea rescue sequence care character u ghost closet costners character realize early forget much later time care character really care cocky overconfident ashton kutcher problem come kid think better anyone else around show sign clutter closet obstacle appear win costner finally well past half way point stinker costner tell u kutchers ghost tell kutcher drive best prior inkling foreshadow magic wa could keep turn hour \n",
            "\n",
            "La phrase vectorisée est : \n",
            " [334, 10, 981, 2, 143, 1042, 1556, 1047, 1217, 1435, 1437, 352, 282, 15, 91, 976, 3454, 15, 454, 337, 414, 24, 219, 11, 282, 15, 20, 282, 213, 39, 154, 19, 59, 173, 254, 104, 21, 1123, 3454, 263, 424, 342, 22, 445, 247, 37, 89, 3223, 84, 91, 976, 84, 492, 53, 2239, 1234, 3, 43, 119, 94, 246] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BA0-Vof9Whn",
        "outputId": "56cf0f29-5cb2-4db3-ed4e-95bdd2b3e04d"
      },
      "source": [
        "# On padde les séquences\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# On padde les séquence de mot\n",
        "max_len = 100\n",
        "X       = pad_sequences(list_tokenized_train, maxlen=max_len)\n",
        "\n",
        "print(\"La phrase paddée sur une longueur {} est : \\n {}\". format(max_len, X[0]))\n",
        "      "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La phrase paddée sur une longueur 100 est : \n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0  334   10  981\n",
            "    2  143 1042 1556 1047 1217 1435 1437  352  282   15   91  976 3454\n",
            "   15  454  337  414   24  219   11  282   15   20  282  213   39  154\n",
            "   19   59  173  254  104   21 1123 3454  263  424  342   22  445  247\n",
            "   37   89 3223   84   91  976   84  492   53 2239 1234    3   43  119\n",
            "   94  246]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihez3i4H9Whn"
      },
      "source": [
        "# On crée les ensembles d'apprentissage et de test\n",
        "\n",
        "# On récupère les données correspondantes aux séquences de mots\n",
        "y       = data['label']\n",
        "typ     = data['type']\n",
        "\n",
        "# Indexes des données pour l'entrainement et le test (tels que spécifiés dans data)\n",
        "i_trn  = [i for i in range(len(typ)) if typ[i]=='train']\n",
        "i_tst  = [i for i in range(len(typ)) if typ[i]=='test']\n",
        "\n",
        "# Données d'entrée\n",
        "X_trn = X[i_trn]\n",
        "X_tst = X[i_tst]\n",
        "# Labels de sorties\n",
        "y_trn = y[i_trn]\n",
        "y_tst = y[i_tst]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyuwj9HV9Whn"
      },
      "source": [
        "## 3. Déclaration du réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJA4Zlyg9Whn",
        "outputId": "1afded48-1fd9-496f-dc1d-e4ddfec412e7"
      },
      "source": [
        "# On importe les librairies pour le RNN\n",
        "from tensorflow.keras.layers import Dense , Input , SimpleRNN, LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution1D\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "embed_size = 128                                                   # dimension de l'embedding\n",
        "RNN_size   = 64\n",
        "\n",
        "# On définit l'architecture du réseau\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))                     # layer embedding\n",
        "model.add((LSTM(RNN_size, return_sequences = True)) )\n",
        "model.add((LSTM(RNN_size, return_sequences = True)) )\n",
        "model.add((LSTM(RNN_size, return_sequences = False)) )\n",
        "           # layer RNN\n",
        "model.add(Dropout(0.5))                                            # layer Dropout\n",
        "model.add(Dense(1))                                                # layer Dense\n",
        "\n",
        "# On affiche l'architecture de notre modèle\n",
        "model.summary()\n",
        "\n",
        "# On spécifie la fonction de perte, l'optimiseur, et la fonction d'évaluation\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, None, 128)         640000    \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, None, 64)          49408     \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, None, 64)          33024     \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 755,521\n",
            "Trainable params: 755,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyG6V_F69Who"
      },
      "source": [
        "## 4. Entrainement du réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnfWbDpk9Who",
        "outputId": "7aad5f6c-27da-447d-a945-af7d7b7f8bf9"
      },
      "source": [
        "# On entraine le réseau\n",
        "batch_size = 32                                                             # tailles des mini-batch\n",
        "epochs = 5        \n",
        "opt = optimizers.Adam(learning_rate=0.01)                                                           # nombre d'époques\n",
        "history = model.fit(X_trn,y_trn, batch_size=batch_size, epochs=epochs, validation_split=0.2) # on entraine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "264/625 [===========>..................] - ETA: 59s - loss: 0.3936 - accuracy: 0.8589"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BweNRXIV9Who"
      },
      "source": [
        "# On prédit sur l'ensemble de test\n",
        "\n",
        "# On prédit sur les données de test\n",
        "y_hat = model.predict(X_tst)\n",
        "\n",
        "# On tranforme les prédictions en labels\n",
        "i_pos = [i for i in range(len(y_hat)) if y_hat[i]>0]\n",
        "i_neg = [i for i in range(len(y_hat)) if y_hat[i]<=0]\n",
        "\n",
        "y_pred   = np.zeros(len(y_hat))\n",
        "y_pred[i_pos] = 1\n",
        "y_pred[i_neg] = 0\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVTeDRtO9Who",
        "outputId": "ac5e3e74-f20a-44ca-ef74-3b9de5bf54e0"
      },
      "source": [
        "# On importe les librairies pour l'évaluation\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# On calcule la matrice de confusion\n",
        "cm_test = confusion_matrix(y_tst, y_pred)\n",
        "print('La matrice de confusion sur le jeu de test :\\n', cm_test, '\\n')\n",
        "\n",
        "# On calcul le score d accuracy\n",
        "acc_train=accuracy_score(y_tst, y_pred)\n",
        "print('L accuracy sur le jeu de test est :\\n', acc_train)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La matrice de confusion sur le jeu de test :\n",
            " [[ 4131  8369]\n",
            " [  183 12317]] \n",
            "\n",
            "L accuracy sur le jeu de test est :\n",
            " 0.65792\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}